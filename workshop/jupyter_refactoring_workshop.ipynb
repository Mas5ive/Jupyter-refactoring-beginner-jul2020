{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Jupyter Refactoring for Beginners\n",
    "\n",
    "<img src=\"../assets/Title.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Workshop structure\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Why Refactoring is needed](#Why-Refactoring-is-needed)\n",
    "- [How to refactor your code (prerequisites)](#How-to-refactor-your-code-(prerequisites))\n",
    "- [How to write cleaner and more efficient code in Pythonic way](#How-to-write-cleaner-and-more-efficient-code-in-Pythonic-way)\n",
    "- [Bonus](#Bonus)\n",
    "- [Q&A time](#Q&A-time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### About me\n",
    "**Alyona Galyeva**: [Principal Data Solutions Engineer at LINKIT](https://www.linkit.nl/en) and [Organiser at PyLadies Amsterdam](https://amsterdam.pyladies.com/)\n",
    "\n",
    "<img src=\"../assets/PyLadies1.jpg\" width=\"800\">  \n",
    "\n",
    "<img src=\"../assets/PyLadies2.jpg\" width=\"800\">  \n",
    "\n",
    "<img src=\"../assets/PyLadies3.jpg\" width=\"800\"> \n",
    "\n",
    "Feel free to contact me via LinkedIn: https://www.linkedin.com/in/alyonagalyeva/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Refactoring is needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Awesome script](https://chezsoi.org/lucas/blog/images/wwcb/Ill_just_write_a_quick_script...-catacrac.net.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to the land of Spaghetti code and Big Ball of Mud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipytest\n",
    "import pytest\n",
    "\n",
    "ipytest.autoconfig()\n",
    "pd.set_option(\"display.max_columns\", None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REPEAT THIS AT HOME !!! IT IS DANGEROUS AND CONTAGIOUS !!!\n",
    "file = \"/Users/alyonagalyeva/tutorials/WIP/Jupyter-refactoring-beginner-jul2020/workshop/data/Boston_housing_prices.csv\"\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "df=pd.read_csv(file, delim_whitespace=True, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/Boston_housing_prices.csv\"\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "df=pd.read_csv(file, delim_whitespace=True, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[df['CHAS'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df[df['AGE']==45.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df.rename(str.lower, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hoerra, we have a function !!!\n",
    "def twicecol(df, dfcol):\n",
    "    df['twicecol'] = df[dfcol] * df[dfcol]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=twicecol(df3, 'nox')\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oops, we mutated original dataframe df3, how it is even possible?\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Refactoring is an essential technique to allow a program to be changed safely. It consists of making small changes that don't alter the observable behavior of the software. \" - *Martin Fowler*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, why do we need Refactoring?**\n",
    "\n",
    "- to understand the code\n",
    "- to improve the readability of code\n",
    "- to make it easier to enhance the code\n",
    "- to reduce time of bug hunting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is Technical Debt?**\n",
    "\n",
    "1. It's a metaphor to describe problems with code design\n",
    "2. It's a lot of shortcuts taken for various reasons\n",
    "3. We borrow against future\n",
    "4. It needs to be paid off with refactoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When to stop Refactoring?**\n",
    "\n",
    "- Stop when your refactoring step becomes too big\n",
    "- Stop when there is no ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to refactor your code (prerequisites)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The art of Recognizing Issues in your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how comments can help or badly hurt you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give new names to the columns by renaming the columns and make each columns lowercase, use axis columns \n",
    "df3=df.rename(str.lower, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation with independent Variable (Note: Models like RF are not linear like these)\n",
    "df.columns\n",
    "df2 = df.drop('MEDV', axis=1)\n",
    "df.corrwith(df['MEDV']).plot.bar(\n",
    "        figsize = (10, 10), title = \"Correlation with MEDV\", fontsize = 15,\n",
    "        rot = 45, grid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusing names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember our friends df, df1, df2 and this awesome function?\n",
    "def twicecol(df, dfcol):\n",
    "    df['twicecol'] = df[dfcol] * df[dfcol]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "magic numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somewhere in notebook\n",
    "val = 6\n",
    "\n",
    "# later somewhere at the end of the notebook\n",
    "grouped = df.groupby('TAX').agg([np.sum, np.mean, np.std])\n",
    "\n",
    "if val > 6:\n",
    "    print(grouped.head())\n",
    "else:\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duplication and large code blocks are dangerous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X and y\n",
    "X = df2\n",
    "y = df.loc[:,'MEDV']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#### Model Building ####\n",
    "### Comparing Models\n",
    "\n",
    "## Multiple Linear Regression Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = regressor.predict(X_test)\n",
    "from sklearn import metrics\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "results = pd.DataFrame([['Multiple Linear Regression', mae, mse, rmse, r2]],\n",
    "               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n",
    "\n",
    "## Suport Vector Regression \n",
    "'Necessary Standard Scaler '\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = regressor.predict(X_test)\n",
    "from sklearn import metrics\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Support Vector RBF', mae, mse, rmse, r2]],\n",
    "               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "## Decision Tree Regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = regressor.predict(X_test)\n",
    "from sklearn import metrics\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Decision Tree Regression', mae, mse, rmse, r2]],\n",
    "               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "poor formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure( figsize=(10, 10) ); plt.suptitle( 'Histograms', fontsize=20 )\n",
    "for i in range(df2.shape[1]):\n",
    "    plt.subplot( 6,3,i+1);f = plt.gca();f.set_title(df2.columns.values[i])\n",
    "\n",
    "    vals = np.size(df2.iloc[:, i].unique())\n",
    "    if vals>=100: vals=100\n",
    "    \n",
    "    plt.hist(df2.iloc[:, i], bins=vals, color='#3F5D7D')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zombie code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_sv = GridSearchCV(desc_tr, cv=kf, param_grid={\"max_depth\" : [1, 2, 3, 4, 5, 6, 7]}, scoring='neg_mean_squared_error')\n",
    "#grid_sv.fit(x_scaled, y)\n",
    "#print(\"Best classifier :\", grid_sv.best_estimator_)\n",
    "\n",
    "#grid_sv = GridSearchCV(knn, cv=kf, param_grid={\"n_neighbors\" : [2, 3, 4, 5, 6, 7]}, scoring='neg_mean_squared_error')\n",
    "#grid_sv.fit(x_scaled, y)\n",
    "#print(\"Best classifier :\", grid_sv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to write cleaner and more efficient code in Pythonic way\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typical refactoring workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- answer why refactoring is needed in this particular situation\n",
    "- git, conda environment (or venv) are your best friends\n",
    "- make a copy of a notebook you are going to refactor\n",
    "- fix the seed\n",
    "- define a layout for your refactored notebook\n",
    "- pick a chunk of code to refactor\n",
    "- if you created a function, write tests for this function, run tests. If success --> git commit\n",
    "- else update your function to make the tests pass --> git commit\n",
    "- repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 0:**\n",
    "\n",
    "Take a look at two notebooks in notebooks_to_refactor folder.\n",
    "\n",
    "Can you recognize some of the issues in the code? \n",
    "\n",
    "Is a goal of the notebooks clear enough?\n",
    "\n",
    "Is a structure of notebooks clear as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are you ready to roll up the sleeves and start hands-on part together with me?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactoring techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename\n",
    "\n",
    "Let's take a look at the most powerful and widely used refactoring technique: **Rename**\n",
    "\n",
    "What we can **Rename**:\n",
    "- a variable\n",
    "- a function\n",
    "- function parameters\n",
    "- a class\n",
    "- class attributes \n",
    "- class methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (\"data/movies_metadata.csv\")\n",
    "df = pd.read_csv(x)\n",
    "df1 = df[df[\"budget\"] > 30000000]\n",
    "\n",
    "#rename variables \n",
    "filepath = (\"data/movies_metadata.csv\")\n",
    "movies = pd.read_csv(filepath, low_memory=False)\n",
    "movies_big_budget = df[df[\"budget\"] > 30000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(a, b):\n",
    "    return a.lower() + b.upper()\n",
    "\n",
    "#Rename function and its parameters \n",
    "def mix_lower_upper_case(first_param, second_param):\n",
    "    return first_param.lower() + second_param.upper()\n",
    "\n",
    "#We can add type hints for readability purposes\n",
    "def mix_lower_upper_case(first_param: str, second_param: str) -> str:\n",
    "    \"\"\" Concatenate two strings, cast the first string to lowercase and the second string to uppercase\"\"\"\n",
    "    return first_param.lower() + second_param.upper()\n",
    "\n",
    "# Add casting to a str to make sure that the function returns what expected\n",
    "def mix_lower_upper_case(first_param: str, second_param: str) -> str:\n",
    "    \"\"\" Concatenate two strings, cast the first string to lowercase and the second string to uppercase\"\"\"\n",
    "    return str(first_param).lower() + str(second_param).upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "Rename a function, add docstring, type hints\n",
    "\n",
    "def refactor_me(x, y, z):\n",
    "    return 2*x+y+z**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract\n",
    "\n",
    "Let's try another refactoring technique: **Extract**\n",
    "\n",
    "What we can **Extract**:\n",
    "- a variable\n",
    "- a function\n",
    "- function parameters\n",
    "- class\n",
    "- class methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_valid_budget = movies.loc[movies[\"budget\"] != 0]\n",
    "\n",
    "# extract a variable\n",
    "valid_budget = movies[\"budget\"] != 0\n",
    "movies_valid_budget = movies.loc[valid_budget]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract a function, but before this we need to add tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "#Our tests\n",
    "def test_say_hello_success():\n",
    "    assert say_hello() == \"Hello Again\"\n",
    "\n",
    "def test_say_hello_failure():\n",
    "    assert say_hello() == \"hello Again\"\n",
    "\n",
    "    \n",
    "#A function to be tested\n",
    "def say_hello():\n",
    "    return \"Hello Again\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "#Our tests\n",
    "#positive case\n",
    "def test_multiply_column_by_2():\n",
    "    input_df = pd.DataFrame([(1, 2), (2, 8)], columns=[\"A\", \"B\"])\n",
    "    test_df = multiply_column(input_df, \"B\", 2)\n",
    "    expected_df = pd.Series([4,16], name=\"B\")\n",
    "    pd.testing.assert_series_equal(test_df, expected_df)\n",
    "\n",
    "#positive case\n",
    "def test_multiply_column_by_min1():\n",
    "    input_df = pd.DataFrame([(1, 2), (2, 8)], columns=[\"A\", \"B\"])\n",
    "    test_df = multiply_column(input_df, \"A\", -1)\n",
    "    expected_df = pd.Series([-1,-2], name=\"A\")\n",
    "    pd.testing.assert_series_equal(test_df, expected_df)\n",
    "   \n",
    "# negative case\n",
    "def test_multiply_column_not_exist():\n",
    "    with pytest.raises(KeyError):\n",
    "        input_df = pd.DataFrame([(1, 2), (2, 8)], columns=[\"A\", \"B\"])\n",
    "        test_df = multiply_column(input_df, \"C\", 0)\n",
    "\n",
    "#Extract a function\n",
    "def multiply_column(df: pd.DataFrame, column_name: str, multiplier: int) -> pd.Series:\n",
    "    df = df.copy()\n",
    "    updated_df = df[column_name] * multiplier\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "Extract a function and 3 tests for the following lines below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_movie_data_df = movie_data_df.loc[movie_data_df[\"budget\"] != 0  ]\n",
    "#clean_movie_data_df = clean_movie_data_df.loc[clean_movie_data_df[\"revenue\"] != 0  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inline\n",
    "\n",
    "Let's move to another refactoring technique: **Inline**\n",
    "\n",
    "What we can **Inline**:\n",
    "- a variable\n",
    "- a function\n",
    "- a class\n",
    "- class attributes\n",
    "- class methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = (\"data/movies_metadata.csv\")\n",
    "movies = pd.read_csv(filepath, low_memory=False)\n",
    "\n",
    "#Inline variable\n",
    "movies = pd.read_csv(\"data/movies_metadata.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move\n",
    "\n",
    "And what about this refactoring technique: **Move**\n",
    "\n",
    "What we can **Move**:\n",
    "- a variable\n",
    "- a function\n",
    "- a class\n",
    "- class methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRegressModel():\n",
    "    \n",
    "    def do_smth(self):\n",
    "        pass\n",
    "    \n",
    "    def do_classification(self, inputs):\n",
    "        pass\n",
    "    \n",
    "# Move a class method\n",
    "class MyRegressModel():\n",
    "    \n",
    "    def do_smth(self):\n",
    "        pass\n",
    "    \n",
    "class MyClassifModel():\n",
    "      \n",
    "    def do_classification(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Jupyter Notebook Refactoring Series - Part 1](https://itnext.io/jupyter-notebook-refactoring-series-part-1-adff1b44dfdb)\n",
    "- [Jupyter Notebook Refactoring Series - Part 2](https://itnext.io/jupyter-notebook-refactoring-series-part-2-899e40163ead)\n",
    "- [Refactoring catalogue](https://refactoring.com/catalog/)\n",
    "- [Refactoring techniques](https://refactoring.guru/refactoring/techniques)\n",
    "\n",
    "- [Data Science Workflow](https://towardsdatascience.com/the-data-science-workflow-43859db0415)\n",
    "- [Structure and Automated Workflow for Data Science Project - Part1](https://towardsdatascience.com/structure-and-automated-workflow-for-a-machine-learning-project-2fa30d661c1e)\n",
    "- [Structure and Automated Workflow for Data Science Project - Part2](https://towardsdatascience.com/structure-and-automated-workflow-for-a-machine-learning-project-part-2-b5b420625102)\n",
    "- [Integrate Unit Testing, Linting and CI into your Python project](https://www.earthdatascience.org/blog/unit-testing-linting-ci-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Reproducible Data Analysis in Jupyter](https://youtu.be/_ZEWDGpM-vM)\n",
    "- [Clean code for ML projects](https://github.com/davified/clean-code-ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A time\n",
    "\n",
    "### Thank you for your time !!!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "jupyter-refactoring",
   "language": "python",
   "name": "jupyter-refactoring"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
